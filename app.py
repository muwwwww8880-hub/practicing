import streamlit as st
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted, InternalServerError
from google.generativeai.types import StopCandidateException, BlockedPromptException
import pandas as pd
import io
import time
from datetime import datetime
import os

# --- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (System Prompt) ---
# ì±—ë´‡ì˜ ì—­í• ê³¼ ì‘ë™ ë°©ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤.
SYSTEM_PROMPT = """
1) ë‹¹ì‹ ì€ ì‚¬ìš©ìì™€ í•¨ê»˜ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ê°€ëŠ” 'ì´ì•¼ê¸° ì‘ê°€ ë´‡'ì…ë‹ˆë‹¤. í•­ìƒ ì¹œì ˆí•˜ê³  ëª…ë‘í•œ ì–´íˆ¬ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”.
2) ì‚¬ìš©ìê°€ ë§Œë“¤ê³  ì‹¶ì€ ì´ì•¼ê¸°ì˜ ì£¼ì œë¥¼ ë¬¼ì–´ë³´ì„¸ìš”. ë§Œì•½ ì‚¬ìš©ìê°€ ì£¼ì œë¥¼ ì¶”ì²œí•´ë‹¬ë¼ê³  í•œë‹¤ë©´, í¥ë¯¸ë¡œìš´ ì£¼ì œë¥¼ 1~2ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.
3) ì£¼ì œê°€ ì •í•´ì§€ë©´, ë‹¹ì‹ ì´ ë¨¼ì € ì´ì•¼ê¸°ì˜ 'ë°œë‹¨' ë¶€ë¶„(ì‹œì‘)ì„ 2-3ì¤„ ì •ë„ë¡œ ì œì‹œí•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì‚¬ìš©ìì—ê²Œ ê·¸ ë’·ì´ì•¼ê¸°ë¥¼ ì´ì–´ì„œ ì‘ì„±í•´ë‹¬ë¼ê³  ìš”ì²­í•˜ì„¸ìš”.
4) ì‚¬ìš©ìê°€ ì‘ë‹µí•˜ë©´, ë‹¹ì‹ ì€ ê·¸ ì´ì•¼ê¸°ì— ì´ì–´ì§€ëŠ” 'ì „ê°œ' ë˜ëŠ” 'ìœ„ê¸°' ë¶€ë¶„ 2-3ì¤„ì„ ì‘ì„±í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ ì´ì•¼ê¸°ê°€ ì™„ì„±ë  ë•Œê¹Œì§€ ë°˜ë³µí•©ë‹ˆë‹¤.
5) ì´ì•¼ê¸°ì˜ êµ¬ì„±(ë°œë‹¨-ì „ê°œ-ìœ„ê¸°-ì ˆì •-ê²°ë§)ì„ ê³ ë ¤í•˜ë©°, ì‚¬ìš©ìì˜ ì´ì•¼ê¸°ì— ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ë‚´ìš©ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
6) ì‚¬ìš©ìê°€ 'ì´ì•¼ê¸°ë¥¼ ë§ˆë¬´ë¦¬í•´ì¤˜'ë¼ê³  ìš”ì²­í•˜ê±°ë‚˜, ë‚´ìš©ìƒ 'ê²°ë§'ì— ë„ë‹¬í–ˆë‹¤ê³  íŒë‹¨ë˜ë©´, ì´ì•¼ê¸° ì‘ì„±ì„ ë§ˆë¬´ë¦¬í•˜ëŠ” ê²°ë¡ ì„ ì‘ì„±í•˜ì„¸ìš”.
7) ì´ì•¼ê¸°ê°€ ì™„ì„±ë˜ë©´, "ì™€, ë©‹ì§„ ì´ì•¼ê¸°ê°€ ì™„ì„±ë˜ì—ˆë„¤ìš”! ì§ì§ì§!" ê°™ì€ ì¹­ì°¬ì˜ ë§ê³¼ í•¨ê»˜,
   ì§€ê¸ˆê¹Œì§€ ì£¼ê³ ë°›ì€ 'ì‚¬ìš©ì'ì™€ 'ë‹¹ì‹ 'ì˜ ëª¨ë“  ì´ì•¼ê¸° ì¡°ê°ë“¤ì„ í•˜ë‚˜ì˜ ì™„ì„±ëœ ê¸€ë¡œ í•©ì³ì£¼ì„¸ìš”.
   ê·¸ë¦¬ê³  ê·¸ ì™„ì„±ëœ ì´ì•¼ê¸°ì— ì–´ìš¸ë¦¬ëŠ” 'ì„ì˜ì˜ ì œëª©'ì„ 1ê°œ ë¶™ì—¬ì„œ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•´ì£¼ì„¸ìš”.
   ë§ˆì§€ë§‰ìœ¼ë¡œ, ì™„ì„±ëœ ì´ì•¼ê¸°ì— ëŒ€í•´ 'í•œ ì¤„ í‰ê°€'ë¥¼ ë‚¨ê²¨ì£¼ì„¸ìš”.

ì˜ˆì‹œ (ì™„ì„± ì‹œ):
---
[ë´‡] ì™€, ë©‹ì§„ ì´ì•¼ê¸°ê°€ ì™„ì„±ë˜ì—ˆë„¤ìš”! ì§ì§ì§!
ìš°ë¦¬ê°€ í•¨ê»˜ ë§Œë“  ì´ì•¼ê¸°ì˜ˆìš”!

ì œëª©: ìš°ì£¼ë¥¼ ì—¬í–‰í•˜ëŠ” ê³ ì–‘ì´, ëƒ¥ì´
(ì—¬ê¸°ë¶€í„° ë´‡ê³¼ ì‚¬ìš©ìê°€ ì£¼ê³ ë°›ì€ ëª¨ë“  ë‚´ìš©ì„ í•©ì¹œ ì™„ì„±ë³¸)
...
...
(ì´ì•¼ê¸° ë)

í•œì¤„ í‰ê°€: ìƒìƒë ¥ì´ ë‹ë³´ì´ëŠ” ì •ë§ ë”°ëœ»í•œ ì´ì•¼ê¸°ì˜€ì–´ìš”!
---
"""

# --- 1. ì•± ì„¤ì • ë° ì´ˆê¸°í™” ---

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì´ì•¼ê¸° ì´ì–´ì“°ê¸° ì±—ë´‡",
    page_icon="âœï¸",
    layout="centered",
    initial_sidebar_state="expanded",
)

st.title("âœï¸ AI ì´ì•¼ê¸° ì´ì–´ì“°ê¸° ì±—ë´‡")
st.write("Gemini AIì™€ í•¨ê»˜ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ íƒí—˜í•˜ê³  ë©‹ì§„ ì´ì•¼ê¸°ë¥¼ ì™„ì„±í•´ë³´ì„¸ìš”!")

@st.cache_data(ttl=3600)
def get_available_models(api_key):
    """Gemini APIì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. (exp ì œì™¸)"""
    try:
        genai.configure(api_key=api_key)
        model_list = []
        for model in genai.list_models():
            if 'generateContent' in model.supported_generation_methods and \
               'exp' not in model.name:
                model_list.append(model.name)
        # 'gemini-2.0-flash'ê°€ ìˆë‹¤ë©´ ìµœìƒë‹¨ìœ¼ë¡œ
        flash_model = "models/gemini-2.0-flash"
        if flash_model in model_list:
            model_list.remove(flash_model)
            model_list.insert(0, flash_model)
        elif "models/gemini-pro" in model_list: # 2.0 í”Œë˜ì‹œê°€ ì—†ì„ ê²½ìš° proë¥¼ ìœ„ë¡œ
             model_list.remove("models/gemini-pro")
             model_list.insert(0, "models/gemini-pro")
        return model_list
    except Exception as e:
        st.error(f"ëª¨ë¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        # API í‚¤ê°€ ì˜ëª»ëœ ê²½ìš° ë“±, ê¸°ë³¸ ëª©ë¡ ë°˜í™˜
        return ["models/gemini-2.0-flash", "models/gemini-pro"]

def init_api_key():
    """API í‚¤ë¥¼ st.secrets ë˜ëŠ” ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤."""
    api_key = st.secrets.get("GEMINI_API_KEY")
    if api_key:
        return api_key
    
    st.sidebar.warning("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. st.secretsì— 'GEMINI_API_KEY'ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    api_key = st.sidebar.text_input("ë˜ëŠ” ì—¬ê¸°ì— Gemini API í‚¤ë¥¼ ì„ì‹œ ì…ë ¥í•˜ì„¸ìš”:", type="password")
    if not api_key:
        st.error("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    return api_key

# --- 2. ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ---

def init_session_state():
    """Streamlit ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if "session_id" not in st.session_state:
        st.session_state.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    if "messages" not in st.session_state:
        st.session_state.messages = []  # UI í‘œì‹œìš©
    if "chat_session" not in st.session_state:
        st.session_state.chat_session = None
    if "log_data" not in st.session_state:
        st.session_state.log_data = [] # CSV ì €ì¥ìš©
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = "models/gemini-2.0-flash" # ê¸°ë³¸ê°’

def start_new_chat_session(model_name, history=None):
    """ìƒˆë¡œìš´ ì±— ì„¸ì…˜ì„ ì‹œì‘í•˜ê±°ë‚˜, ê¸°ì¡´ ê¸°ë¡ìœ¼ë¡œ ì„¸ì…˜ì„ ë³µì›í•©ë‹ˆë‹¤."""
    try:
        model = genai.GenerativeModel(
            model_name,
            system_instruction=SYSTEM_PROMPT,
            generation_config={"temperature": 0.8} # ì°½ì˜ì„±ì„ ìœ„í•´ ì˜¨ë„ë¥¼ ì•½ê°„ ë†’ì„
        )
        
        # 'history'ëŠ” {role: "user"/"model", "parts": [text]} ë¦¬ìŠ¤íŠ¸
        formatted_history = []
        if history:
            for msg in history:
                formatted_history.append({
                    "role": "user" if msg["role"] == "user" else "model",
                    "parts": [msg["content"]]
                })
        
        st.session_state.chat_session = model.start_chat(history=formatted_history)
        st.session_state.selected_model = model_name
        
    except Exception as e:
        st.error(f"ì±— ì„¸ì…˜ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

def clear_chat_history():
    """ëª¨ë“  ëŒ€í™” ê¸°ë¡ê³¼ ì„¸ì…˜ ì •ë³´ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    st.session_state.messages = []
    st.session_state.log_data = []
    st.session_state.chat_session = None # ì„¸ì…˜ ê°ì²´ ì´ˆê¸°í™”
    st.session_state.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    st.rerun()

def prune_and_restart_session(keep_messages=6):
    """
    API í•œë„(429)ì— ë„ë‹¬í–ˆì„ ë•Œ,
    ìµœê·¼ Nê°œì˜ ë©”ì‹œì§€ë§Œ ë‚¨ê¸°ê³  ì„¸ì…˜ì„ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤.
    """
    st.warning(f"API í•œë„(429) ë„ë‹¬. ìµœê·¼ {keep_messages}ê°œ(3í„´)ì˜ ëŒ€í™”ë§Œ ë‚¨ê¸°ê³  ì„¸ì…˜ì„ ì¬ì‹œì‘í•©ë‹ˆë‹¤.")
    time.sleep(2) # ê°„ë‹¨í•œ ë°±ì˜¤í”„

    # UI/Log ê¸°ë¡ ì¶•ì†Œ
    st.session_state.messages = st.session_state.messages[-keep_messages:]
    st.session_state.log_data = st.session_state.log_data[-keep_messages:]

    # ìƒˆ ì„¸ì…˜ ì‹œì‘ (ì¶•ì†Œëœ ê¸°ë¡ ì‚¬ìš©)
    start_new_chat_session(
        st.session_state.selected_model,
        history=st.session_state.messages
    )

# --- 3. UI ë° ìƒí˜¸ì‘ìš© (ì‚¬ì´ë“œë°”) ---

# API í‚¤ ê°€ì ¸ì˜¤ê¸°
API_KEY = init_api_key()
MODELS = get_available_models(API_KEY)

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("ì„¤ì •")

# ëª¨ë¸ ì„ íƒ
selected_model_name = st.sidebar.selectbox(
    "AI ëª¨ë¸ ì„ íƒ",
    options=MODELS,
    index=MODELS.index(st.session_state.selected_model) if st.session_state.selected_model in MODELS else 0,
    help="ì´ì•¼ê¸° ë§Œë“¤ê¸°ì— ì‚¬ìš©í•  Gemini ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤."
)

# ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆìœ¼ë©´ ì„¸ì…˜ ì´ˆê¸°í™”
if selected_model_name != st.session_state.selected_model:
    clear_chat_history()
    start_new_chat_session(selected_model_name, history=None) # ìƒˆ ëª¨ë¸ë¡œ ì„¸ì…˜ ì‹œì‘

# ìƒˆ ì´ì•¼ê¸° ì‹œì‘ ë²„íŠ¼
st.sidebar.button("ìƒˆ ì´ì•¼ê¸° ì‹œì‘", on_click=clear_chat_history, use_container_width=True)

# CSV ê¸°ë¡ ì˜µì…˜
log_enabled = st.sidebar.checkbox("ëŒ€í™” ìë™ ê¸°ë¡ (CSV)", value=True, help="ì²´í¬í•˜ë©´ ëª¨ë“  ëŒ€í™”ê°€ CSV ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ ì„ì‹œ ì €ì¥ë©ë‹ˆë‹¤.")

# ë¡œê·¸ ë‹¤ìš´ë¡œë“œ
def get_log_csv():
    """ì„¸ì…˜ ë¡œê·¸ë¥¼ CSV íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not st.session_state.log_data:
        return ""
    log_df = pd.DataFrame(st.session_state.log_data)
    # utf-8-sig: ì—‘ì…€ì—ì„œ í•œê¸€ ê¹¨ì§ ë°©ì§€
    return log_df.to_csv(index=False).encode('utf-8-sig')

st.sidebar.download_button(
    label="ëŒ€í™” ê¸°ë¡ ë‹¤ìš´ë¡œë“œ (CSV)",
    data=get_log_csv(),
    file_name=f"chat_log_{st.session_state.session_id}.csv",
    mime="text/csv",
    use_container_width=True,
    disabled=not st.session_state.log_data
)

# ì„¸ì…˜ ì •ë³´ í‘œì‹œ
st.sidebar.markdown("---")
st.sidebar.subheader("ì„¸ì…˜ ì •ë³´")
st.sidebar.info(f"""
**Model:** `{st.session_state.selected_model.split('/')[-1]}`
**Session ID:** `{st.session_state.session_id}`
""")

# --- 4. ë©”ì¸ ì±— ë¡œì§ ---

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì²˜ìŒ ì‹¤í–‰ ì‹œ)
init_session_state()

# ì±— ì„¸ì…˜ì´ ì—†ëŠ” ê²½ìš° (ì²« ì‹¤í–‰ ë˜ëŠ” ì´ˆê¸°í™” í›„) ì‹œì‘
if st.session_state.chat_session is None:
    start_new_chat_session(selected_model_name, history=None)

# ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ì—¬ê¸°ì— ì´ì•¼ê¸°ë‚˜ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ UI ë° ë¡œê·¸ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    if log_enabled:
        st.session_state.log_data.append({
            "timestamp": datetime.now(),
            "session_id": st.session_state.session_id,
            "model": st.session_state.selected_model,
            "role": "user",
            "content": prompt
        })
    
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        with st.spinner("AIê°€ ì´ì•¼ê¸°ë¥¼ ì‡ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                # Gemini API í˜¸ì¶œ
                response = st.session_state.chat_session.send_message(prompt)
                bot_response = response.text
                
            except ResourceExhausted as e:
                # 429 ì˜¤ë¥˜ (API í•œë„ ì´ˆê³¼) ì²˜ë¦¬
                prune_and_restart_session(keep_messages=6)
                # ì¬ì‹œë„
                try:
                    response = st.session_state.chat_session.send_message(prompt)
                    bot_response = response.text
                except Exception as e2:
                    st.error(f"ì¬ì‹œë„ ì‹¤íŒ¨: {e2}")
                    bot_response = None
            
            except (StopCandidateException, BlockedPromptException) as e:
                st.error("âš ï¸ ì•ˆì „ ì„¤ì •ì— ì˜í•´ ì‘ë‹µì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì œë¡œ ì´ì•¼ê¸°í•´ ì£¼ì„¸ìš”.")
                bot_response = None
            
            except InternalServerError as e:
                st.error("ğŸ”Œ í˜„ì¬ Gemini API ì„œë²„ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (500) ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                st.error(f"ì˜¤ë¥˜ ìƒì„¸: {e}")
                bot_response = None

            except Exception as e:
                st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                bot_response = None

            # 3. AI ì‘ë‹µ UI ë° ë¡œê·¸ì— ì¶”ê°€
            if bot_response:
                message_placeholder.markdown(bot_response)
                st.session_state.messages.append({"role": "assistant", "content": bot_response})
                if log_enabled:
                    st.session_state.log_data.append({
                        "timestamp": datetime.now(),
                        "session_id": st.session_state.session_id,
                        "model": st.session_state.selected_model,
                        "role": "assistant",
                        "content": bot_response
                    })